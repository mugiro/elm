% Generated by roxygen2 (4.1.1): do not edit by hand
% Please edit documentation in R/AllGenerics.R
\name{addNeurons}
\alias{addNeurons}
\title{Add hidden neurons to the SLFN}
\usage{
addNeurons(object, ...)
}
\arguments{
\item{object}{An instance to the SLFN class.}

\item{...}{}

\item{number}{The number of hidden neurons to add to the network.}

\item{type}{The activation function of the added neurons. Several types:
#' \itemize{
\item "linear" A standard linear function.
\item "sigmoid" A mathematical function having an "S" shape.
\item "tan"
\item "rbf"
}}

\item{W}{An input weight matrix of dimension [dxL]. List of centroids for
rbf activation functions.}

\item{B}{input bias vector of dimension [1xL]. Vector of sigmas for rbf activation functions.}
}
\value{
object SLFN with new neurons added and W and B matrices updated.

It is called by the training wrapper when a new SLFN object is created. It is called sequentially
based on the different type of activation functions.

When addNeurons is called explicitly, the SLFN should be re-trained

For linear activation functions, the number of neurons added cannot be superior to the number of features (L=<d).
This case entails a linear projection of datato a higher dimensional, which yields a multicorrelated new space.
}
\description{
\code{addNeurons} adds a specific number of hidden neurons to the SLFN being
 all of them of the same type of activation function.
}

