% Generated by roxygen2 (4.1.1): do not edit by hand
% Please edit documentation in R/add_neurons.R
\name{add_neurons}
\alias{add_neurons}
\title{Add hidden neurons to the SLFN.}
\usage{
add_neurons(object, ...)
}
\arguments{
\item{object}{An instance to the SLFN class.}

\item{nn}{The number of hidden neurons to add to the network.}

\item{act_fun}{The activation function of the added neurons. Several types:
\itemize{
\item "linear" A standard linear function.
\item "sigmoid" A mathematical function having an "S" shape.
\item "tan"
\item "rbf"
}}

\item{w_in}{An input weight matrix of dimension [dxL]. List of centroids for
rbf activation functions.}

\item{b}{An input bias vector of dimension [1xL]. Vector of sigmas for
rbf activation functions.}
}
\value{
An object SLFN with new neurons added and w_in and b matrices updated.

It is called by the training wrapper when a new SLFN object is created.
It is called sequentially based on the different type of activation functions.

When addNeurons is called explicitly, the SLFN should be re-trained

For linear activation functions, the number of neurons added cannot be
 superior to the number of features (L=<d). This case entails a linear
 projection of data to a higher dimensional, which yields a multicorrelated
 new space.
}
\description{
\code{add_neurons} adds a specific number of hidden neurons to the SLFN being
 all of them of the same type of activation function.
}

