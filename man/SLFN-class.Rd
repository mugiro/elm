% Generated by roxygen2 (4.1.1): do not edit by hand
% Please edit documentation in R/SLFNclass.R, R/add_neurons.R, R/errors.R, R/predict.R, R/ranking.R, R/train.R, R/train_pruning.R
\docType{class}
\name{SLFN-class}
\alias{SLFN-class}
\alias{add_neurons,SLFN-method}
\alias{class_postprocess,SLFN-method}
\alias{get_error,SLFN-method}
\alias{mse,SLFN-method}
\alias{project,SLFN-method}
\alias{prune,SLFN-method}
\alias{rank_neurons,SLFN-method}
\alias{solve_system,SLFN-method}
\alias{train,SLFN-method}
\alias{train_pruning,SLFN-method}
\title{Class \code{"SLFN"}}
\usage{
\S4method{add_neurons}{SLFN}(object, act_fun, nn, w_in = NULL, b = NULL)

\S4method{get_error}{SLFN}(object, n_sel, h, y, h_val = NULL, y_val = NULL,
  cv_rows = NULL)

\S4method{mse}{SLFN}(object, y, yp, x)

\S4method{class_postprocess}{SLFN}(object, yp, class_output, ml_threshold)

\S4method{rank_neurons}{SLFN}(object, nn_max, h = NULL, y = NULL)

\S4method{train}{SLFN}(object, x, y, x_val = NULL, y_val = NULL,
  type = "reg", tune = "none", ranking = "random", validation = "none",
  folds = 10, class_weights = NULL, ...)

\S4method{project}{SLFN}(object, x, rbf_dist = "euclidean")

\S4method{solve_system}{SLFN}(object, h, y, solve = TRUE)

\S4method{train_pruning}{SLFN}(object, h, y, h_val = NULL, y_val = NULL,
  cv_rows = NULL)

\S4method{prune}{SLFN}(object, n_sel)
}
\description{
A class for defining a Single-hidden Layer Feed-forward Network (SLFN)
}
\details{
Include here more details <<<<<<ANDRES<<<<<<
}
\section{Methods (by generic)}{
\itemize{
\item \code{add_neurons}: add neurons of the same type of activation function to the hidden layer

\item \code{get_error}: implement a validation procedure

\item \code{mse}: MSE error

\item \code{class_postprocess}: 

\item \code{rank_neurons}: rank neurons of a SLFN

\item \code{train}: train the SLFN

\item \code{project}: project form input-space to neuron-space. Compute H

\item \code{solve_system}: solve linear system H x Wout = Y

\item \code{train_pruning}: optimization algorithm for obtaining the optimial number of neurons for pruning

\item \code{prune}: prune a SLFN
}}
\section{Slots}{

\describe{
\item{\code{inputs}}{The number of input features.}

\item{\code{outputs}}{The number of outputs.}

\item{\code{neurons}}{A list that describes the hidden layer. The hidden layer
can be composed by neurons with different activation functions. Each element
of the list includes neurons with the same activation function. The element
is labelled with the type of activation function and contains the following
information: number of neurons (number), input weight vector (W) and biases
(B) associated to all the neurons included.}

\item{\code{w_out}}{The weight output vector that includes the computed weights between
the hidden and the output layer.
      output weights - vector (1 output) / matrix (n outputs)}

\item{\code{results}}{The error used to evaluate model performance.
mse c(mse_train, mse_val)}

\item{\code{ridge}}{The regularization parameter of the network.
normalization H'H solution (ridge parameter)}

\item{\code{type}}{The of model implmented:
\itemize{
\item "reg": regression problem.
\item "class_mc": multi-class: the sample belongs to 1 class out of n.
\item "class_ml": multi-label: the sample can belong to m classes out of n (m<n).
\item "class_w":  weigted classification
}}

\item{\code{tune}}{A character to define the model structure selection method
implemented
#' \itemize{
\item "none"
\item "pruning"
}}

\item{\code{ranking}}{A character to select the type of ranking implemented when
 prunning option is selected.
\itemize{
\item "random" - random ranking
\item "lars" - ranking based on lars - L1 penalty
}}

\item{\code{nnRank}}{An integer that defines teh maximum number of neurons in ranking}

\item{\code{validation}}{The validation procedure used for developing the model.
#' \itemize{
\item "none" - no validation process  <<<<<<ANDRES<<<<<<
\item "v" - validation. Xv and Yv are required
\item "cv" - cross validation. The number of folds is required
\item "loo" - leave one out based on the PRESS statistic
}}

\item{\code{folds}}{The number number of folds for the cross-validation procedure.}

\item{\code{class_weights}}{numeric vector of length = number_of_classes with the weigths for weighted type}

\item{\code{batch}}{The size of the bacth in an adaptative ELM.}

\item{\code{time_exec}}{The time of calculation for training the model.}

\item{\code{bigdata}}{An logical parameter to select the kind of acceleration used in
case of solving big data problems.}
}}
\keyword{classes}

